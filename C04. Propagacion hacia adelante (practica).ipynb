{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación hacia adelante (forward propagation)\n",
    "\n",
    "Vamos a implementar una red neuronal con capacidad de hacer predicciones mediante la propagación hacia adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos\n",
    "\n",
    "Vamos a usar el dataset del cancer de mama (Breast Cancer Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar la red neuronal que hemos visto con 4 unidades en la capa de entrada, usaremos solo las 4 primeras variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar modelos de deep learning es importante que las variables estén en la misma escala, por ello vamos a estandarizar las variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_estandardizador = StandardScaler()\n",
    "X_std = x_estandardizador.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ésta es el modelo que vamos a crear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](im22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, tenemos que definir una capa, creamos la clase `Layer` que tiene una dimension de entrada, una de salida, y una función de activación\n",
    "\n",
    "Inicialmente sus pesos se generan al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, dim_input, dim_output, fn_activacion, nombre):\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_output = dim_output\n",
    "        self.generar_pesos((dim_output, dim_input))\n",
    "        self.generar_bias(dim_output)\n",
    "        self.fn_activacion = fn_activacion\n",
    "        self.nombre = nombre\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"\"\"\n",
    "        Capa {}. tamaño input: {}. tamaño output: {}.\n",
    "        pesos: {}\n",
    "        bias: {}\n",
    "        \"\"\".format(\n",
    "        self.nombre, self.dim_input, self.dim_output,\n",
    "        self.w, self.b)\n",
    "    \n",
    "    def generar_pesos(self, dimensiones):\n",
    "        self.w = np.random.random(dimensiones)\n",
    "        \n",
    "    def generar_bias(self, dim_output):\n",
    "        self.b = np.random.random((dim_output,))\n",
    "    \n",
    "    def activar(self, x):\n",
    "        return self.fn_activacion(self.w @ x + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer propagación hacia adelante necesitamos la función de activación,  en este ejemplo voy a usar la función sigmoide como activación de la capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 4\n",
    "n_oculta = 5\n",
    "n_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capa_oculta = Layer(n_input, n_oculta, fn_sigmoide, \"oculta\")\n",
    "\n",
    "capa_salida = Layer(n_oculta, n_output, fn_sigmoide, \"salida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(capa_oculta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear una red neuronal, que básicamente tiene una lista con las capas que tiene y el método para la propagación hacia adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedNeuronal:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"\"\"\n",
    "        input {}\n",
    "        \"\"\".format(x))\n",
    "        for layer in self.layers:\n",
    "            x = layer.activar(x)\n",
    "            print(layer)\n",
    "            print(\"\"\"\n",
    "            output: {}\n",
    "            \"\"\".format(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = RedNeuronal()\n",
    "\n",
    "red.add_layer(capa_oculta)\n",
    "red.add_layer(capa_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_aleatorio = np.random.permutation(X.shape[0])\n",
    "\n",
    "x0 = X_std[indice_aleatorio[0]]\n",
    "y0 = y[indice_aleatorio[0]]\n",
    "print(x0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.forward(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
