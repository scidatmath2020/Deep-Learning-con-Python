{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización en Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En deep learning no se suele hacer validación cruzada (a menos que el tamaño del dataset y el tiempo de entrenamiento lo permita). En lugar de eso se hacen simples separaciónes entre datos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=IntSlider(min=0,max=50,step=1,value=1))\n",
    "def dibujar_numero(i):\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    plt.title(\"Número {}\".format(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\" #tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_plano = x_train.reshape(x_train.shape[0],28*28)\n",
    "x_test_plano = x_test.reshape(x_test.shape[0],28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_plano[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_plano[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo.add(Dense(250, activation=\"relu\"))\n",
    "modelo.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo.fit(x_train_plano, y_train_one_hot, epochs=50, batch_size=1000, verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver ahora como se compara el funcionamiento del modelo respecto a los datos de entrenamiento y los de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluacion_train = modelo.evaluate(x_train_plano, y_train_one_hot)\n",
    "evaluacion_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluacion_test = modelo.evaluate(x_test_plano, y_test_one_hot)\n",
    "evaluacion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS[\"sin_regularizacion\"] = [evaluacion_train[1], evaluacion_test[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización l1, o l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras permite regularizar los pesos, los sesgos (bias) y las activaciones de  forma independiente, pasando el parámetro `kernel_regularizer`, `bias_regularizer` y `activity_regularizer` respectivamente.\n",
    "\n",
    "Keras tiene los penalizadores `l1`, `l2` y `l1_l2` (elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "modelo_l2 = Sequential()\n",
    "modelo_l2.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo_l2.add(Dense(250, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
    "modelo_l2.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo_l2.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo_l2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_l2.fit(x_train_plano, y_train_one_hot, verbose=0, epochs=50, batch_size=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = modelo_l2.evaluate(x_train_plano, y_train_one_hot)[1]\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = modelo.evaluate(x_test_plano, y_test_one_hot)[1]\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS[\"regularizacion_l2\"] = [acc_train, acc_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos lo mismo pero con regularización l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_l1 = Sequential()\n",
    "modelo_l1.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo_l1.add(Dense(250, activation=\"relu\", kernel_regularizer=regularizers.l1(0.01)))\n",
    "modelo_l1.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo_l1.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo_l1.fit(x_train_plano, y_train_one_hot, verbose=0, epochs=50, batch_size=1000)\n",
    "\n",
    "acc_train = modelo_l1.evaluate(x_train_plano, y_train_one_hot)[1]\n",
    "acc_test = modelo_l1.evaluate(x_test_plano, y_test_one_hot)[1]\n",
    "\n",
    "RESULTADOS[\"regularizacion_l1\"] = [acc_train, acc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a añadir Dropout a la misma red. Dropout simplemente ignora un porcentaje `p` de las unidades (neuronas) en cada iteración del entrenamiento (forward prop y backprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_dropout = Sequential()\n",
    "modelo_dropout.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo_dropout.add(Dense(250, activation=\"relu\"))\n",
    "modelo_dropout.add(Dropout(0.2))\n",
    "modelo_dropout.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo_dropout.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo_dropout.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el número de parámetros a entrenar es el mismo, Dropout no añade pesos a la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo_dropout.fit(x_train_plano, y_train_one_hot, verbose=0, epochs=50, batch_size=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = modelo_dropout.evaluate(x_train_plano, y_train_one_hot)[1]\n",
    "acc_test = modelo_dropout.evaluate(x_test_plano, y_test_one_hot)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS[\"regularizacion_dropout\"] = [acc_train, acc_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización en bloques (batch normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bnorm = Sequential()\n",
    "modelo_bnorm.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo_bnorm.add(Dense(250, activation=\"relu\"))\n",
    "modelo_bnorm.add(BatchNormalization())\n",
    "modelo_bnorm.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo_bnorm.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo_bnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bnorm.fit(x_train_plano, y_train_one_hot, verbose=0, epochs=50, batch_size=1000)\n",
    "acc_train = modelo_bnorm.evaluate(x_train_plano, y_train_one_hot)[1]\n",
    "acc_test = modelo_bnorm.evaluate(x_test_plano, y_test_one_hot)[1]\n",
    "\n",
    "RESULTADOS[\"batch_normalization\"] = [acc_train, acc_test]\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization + Dropout\n",
    "\n",
    "Una práctica común es poner normalizacion batch y dropout juntos en una capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bnorm_drop = Sequential()\n",
    "modelo_bnorm_drop.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "modelo_bnorm_drop.add(Dense(250, activation=\"relu\"))\n",
    "modelo_bnorm_drop.add(BatchNormalization())\n",
    "modelo_bnorm_drop.add(Dropout(0.2))\n",
    "modelo_bnorm_drop.add(Dense(np.unique(y_train).shape[0], activation=\"softmax\"))\n",
    "\n",
    "modelo_bnorm_drop.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", \n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "modelo_bnorm_drop.fit(x_train_plano, y_train_one_hot, verbose=0, epochs=50, batch_size=1000)\n",
    "acc_train = modelo_bnorm_drop.evaluate(x_train_plano, y_train_one_hot)[1]\n",
    "acc_test = modelo_bnorm_drop.evaluate(x_test_plano, y_test_one_hot)[1]\n",
    "\n",
    "RESULTADOS[\"batch_normalization + dropout\"] = [acc_train, acc_test]\n",
    "print(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora metemos los resultados en un dataframe para inspeccionarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultados = pd.DataFrame(RESULTADOS).T\n",
    "resultados.columns = [\"acc_train\", \"acc_test\"]\n",
    "resultados[\"pct_diff\"] = 1 - (resultados.acc_test / resultados.acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort_values(by=\"pct_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
